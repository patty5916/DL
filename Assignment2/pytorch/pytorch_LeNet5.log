Filename: main.py

Line #    Mem usage    Increment  Occurences   Line Contents
============================================================
    25    372.1 MiB    372.1 MiB           1   @profile(stream=open('pytorch_LeNet5.log', 'w+'))
    26                                         def main():
    27    372.1 MiB      0.0 MiB           1       args = parse_args()
    28    372.1 MiB      0.0 MiB           2       transform = transforms.Compose([transforms.ToPILImage(),
    29    372.1 MiB      0.0 MiB           1                                       transforms.Resize((128, 128)),
    30    372.1 MiB      0.0 MiB           1                                       transforms.ToTensor(),
    31    372.1 MiB      0.0 MiB           1                                       transforms.Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225))])
    32                                         
    33    392.2 MiB     20.1 MiB           1       train_data = ImageDataset('train', transform)
    34    392.2 MiB      0.0 MiB           1       val_data = ImageDataset('val', transform)
    35                                         
    36    392.2 MiB      0.0 MiB           1       train_loader = DataLoader(train_data, args.train_batch, shuffle=True, num_workers=0)
    37    392.2 MiB      0.0 MiB           1       val_loader = DataLoader(val_data, 1, shuffle=False, num_workers=0)
    38                                         
    39    394.0 MiB      1.7 MiB           1       device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')
    40    402.7 MiB      8.7 MiB           1       model = LeNet5()
    41   2359.9 MiB   1957.2 MiB           1       model = model.to(device)
    42   2359.9 MiB      0.0 MiB           1       criterion = nn.CrossEntropyLoss()
    43   2359.9 MiB      0.0 MiB           1       optimizer = torch.optim.SGD(model.parameters(), lr=args.lr, momentum=0.8)
    44                                         
    45   2359.9 MiB      0.0 MiB           1       total_time = 0
    46                                             # train
    47   2359.9 MiB      0.0 MiB           1       train_accList= []
    48   2359.9 MiB      0.0 MiB           1       val_accList = []
    49   2359.9 MiB      0.0 MiB           1       lossList = []
    50   2955.2 MiB    -21.7 MiB         201       for epoch in range(args.epochs):
    51   2955.2 MiB    -21.6 MiB         200           start = timeit.default_timer()
    52   2955.2 MiB    -21.6 MiB         200           train_loss = 0
    53   2955.2 MiB    -21.6 MiB         200           val_loss = 0
    54   2955.2 MiB    -21.6 MiB         200           train_acc = 0
    55   2955.2 MiB    -21.6 MiB         200           val_acc = 0
    56   2955.2 MiB    -21.6 MiB         200           best_acc = 0
    57   2955.2 MiB    -21.3 MiB         200           best_model_parameters = copy.deepcopy(model.state_dict())
    58                                         
    59   2955.2 MiB    -21.6 MiB         200           model.train()
    60   3147.2 MiB 2372579.4 MiB       12600           for data, label in train_loader:
    61   2955.2 MiB -2382471.5 MiB       12400               data = data.to(device)
    62   2955.2 MiB  -1670.2 MiB       12400               label = label.to(device)
    63                                         
    64   2955.2 MiB  -1670.2 MiB       12400               optimizer.zero_grad()
    65   2955.2 MiB  -1626.5 MiB       12400               output = model(data)
    66   2955.2 MiB  -1664.7 MiB       12400               loss = criterion(output, label)
    67   2955.2 MiB  -1668.1 MiB       12400               loss.backward()
    68   2955.2 MiB  -1669.9 MiB       12400               optimizer.step()
    69                                         
    70   2955.2 MiB  -1669.8 MiB       12400               train_loss += loss.item() * data.size(0)
    71   2955.2 MiB  -1672.9 MiB       12400               train_acc += torch.sum(torch.argmax(output, axis=1) == label).cpu().numpy()
    72   2955.2 MiB -38460.0 MiB         200           stop = timeit.default_timer()
    73                                         
    74                                                 # validation
    75   2955.2 MiB    -22.3 MiB         200           model.eval()
    76   2955.2 MiB -10041.4 MiB       90200           for data, label in val_loader:
    77   2955.2 MiB -10021.3 MiB       90000               data = data.to(device)
    78   2955.2 MiB -10021.3 MiB       90000               label = label.to(device)
    79                                         
    80   2955.2 MiB -10021.1 MiB       90000               output = model(data)
    81   2955.2 MiB -10021.2 MiB       90000               loss = criterion(output, label)
    82                                         
    83   2955.2 MiB -10021.2 MiB       90000               val_loss += loss.item() * data.size(0)
    84   2955.2 MiB -10021.2 MiB       90000               val_acc += torch.sum(torch.argmax(output, axis=1) == label).cpu().numpy()
    85                                         
    86   2955.2 MiB    -21.8 MiB         200           train_loss /= len(train_loader.sampler)
    87   2955.2 MiB    -21.8 MiB         200           lossList.append(train_loss)
    88                                         
    89   2955.2 MiB    -21.8 MiB         200           train_acc /= len(train_loader.sampler)
    90   2955.2 MiB    -21.8 MiB         200           val_acc /= len(val_loader.sampler)
    91   2955.2 MiB    -21.8 MiB         200           train_accList.append(train_acc)
    92   2955.2 MiB    -21.8 MiB         200           val_accList.append(val_acc)
    93                                         
    94   2955.2 MiB    -21.8 MiB         200           if val_acc > best_acc:
    95   2955.2 MiB    -21.8 MiB         200               best_acc = val_acc
    96   2955.2 MiB    -21.6 MiB         200               best_model_parameters = copy.deepcopy(model.state_dict())
    97                                         
    98   2955.2 MiB    -21.7 MiB         200           total_time += (stop - start)
    99   2955.2 MiB    -21.7 MiB         200           print(f'Epochs: {epoch}\t|Loss: {train_loss}\t|Train Acc: {train_acc}\t|Val Acc: {val_acc}\t|Time: {stop - start}')
   100                                         
   101   2955.1 MiB     -0.1 MiB           1       print(f'Best validation accuracy: {best_acc}')
   102   2955.1 MiB      0.0 MiB           1       model.load_state_dict(best_model_parameters)
   103   2955.1 MiB      0.0 MiB           1       torch.save(model.state_dict(), 'pytorch_LeNet5.pt')
   104                                         
   105                                             # plot
   106   2955.1 MiB      0.0 MiB           1       print(len(train_accList), len(val_accList), len(list(range(args.epochs))))
   107   2958.6 MiB      3.6 MiB           1       plot_acc(train_accList, val_accList, list(range(args.epochs)), 'pytorch_LeNet5_acc.png')
   108   2958.6 MiB      0.0 MiB           1       plot_loss(lossList, 'pytorch_LeNet5_loss.png')
   109                                         
   110                                             # test
   111   2958.6 MiB      0.0 MiB           1       test_data = ImageDataset('test', transform)
   112   2958.6 MiB      0.0 MiB           1       test_loader = DataLoader(test_data, 1, shuffle=False, num_workers=0)
   113                                             
   114   2958.6 MiB      0.0 MiB           1       model.load_state_dict(torch.load('pytorch_LeNet5.pt'))
   115   2958.6 MiB      0.0 MiB           1       model.to(device)
   116                                         
   117   2958.6 MiB      0.0 MiB           1       model.eval()
   118   2958.6 MiB      0.0 MiB           1       test_acc = 0
   119   2958.6 MiB      0.0 MiB         451       for data, label in test_loader:
   120   2958.6 MiB      0.0 MiB         450           data = data.to(device)
   121   2958.6 MiB      0.0 MiB         450           label = label.to(device)
   122   2958.6 MiB      0.0 MiB         450           output = model(data)
   123   2958.6 MiB      0.0 MiB         450           test_acc += torch.sum(torch.argmax(output, axis=1) == label).cpu().numpy()
   124                                         
   125   2958.6 MiB      0.0 MiB           1       test_acc /= len(test_loader.sampler)
   126   2958.6 MiB      0.0 MiB           1       print(f'Test accuracy: {test_acc}')
   127   2958.6 MiB      0.0 MiB           1       print(f'Total Time: {total_time}')


